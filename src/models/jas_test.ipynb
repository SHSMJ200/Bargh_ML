{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "  # This Cell adds model estimate as a column of Data\n",
    "model = None\n",
    "df2 = pd.read_csv(\"U:/ML_project/bargh/data/processed/integrated.csv\", encoding='utf-8')\n",
    "df2.loc[~df2['status'].isin(['SO', 'LF1']), 'status'] = 'SO'\n",
    "df2.loc[~df2['value'].isin(['P']), 'value'] = 'P'\n",
    "df2.drop(columns=feature_to_be_dropped, axis=1, inplace=True)\n",
    "\n",
    "categorical_cols = df2.select_dtypes(include=['object', 'category']).columns\n",
    "df2 = pd.get_dummies(df2, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "X_all = df2.drop(columns=[\"generation\"])\n",
    "y_all = df2[\"generation\"]\n",
    "\n",
    "y_pred = model.pred(X_all)\n",
    "df3 = pd.read_csv(\"U:/ML_project/bargh/data/processed/integrated.csv\", encoding='utf-8')\n",
    "df3['prediction'] = y_pred\n",
    "df3.to_csv('U:/ML_project/bargh/data/processed/with_prediction.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca9a2bcd3a7e60fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "project_root = \"U:/ML_project/bargh\"\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import pandas as pd\n",
    "from data_selector import Data_selector\n",
    "from feature_modifier import Feature_selector, Feature_adder\n",
    "from logs.logger import CustomLogger\n",
    "from models import Random_Forest, Linear, Polynomial, XGBoost\n",
    "\n",
    "logger = CustomLogger(name=\"model_main\", log_file_name='model_main.log').get_logger()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = os.path.join(project_root, \"data\", \"processed\", \"integrated.csv\")\n",
    "df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "logger.info(f\"Csv file has bean read successfully\")\n",
    "\n",
    "feature_adder = Feature_adder(df)\n",
    "feature_adder.add_season()\n",
    "feature_adder.create_feature_with_delay(\"temperature\", 1)\n",
    "feature_adder.create_feature_with_delay(\"temperature\", 2)\n",
    "feature_adder.create_feature_with_delay(\"temperature\", 3)\n",
    "feature_adder.create_feature_with_delay(\"generation\", 1)\n",
    "feature_adder.create_feature_with_delay(\"generation\", 2)\n",
    "feature_adder.create_feature_with_delay(\"generation\", 3)\n",
    "feature_adder.create_feature_with_delay(\"generation\", 24)\n",
    "\n",
    "logger.info(f\"Some features have been added successfully\")\n",
    "\n",
    "data_selector = Data_selector(feature_adder.df)\n",
    "df_modified = data_selector.select(m_in_summer=True)\n",
    "logger.info(f\"Rows have been selected successfully\")\n",
    "feature_selector = Feature_selector(df_modified, \"generation\")\n",
    "feature_to_be_dropped = ['id', 'date', 'declare', 'require']\n",
    "X, y = feature_selector.select(feature_to_be_dropped)\n",
    "logger.info(f\"Some features have been dropped successfully\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e08e2618cfb0dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_numeric = df_modified.select_dtypes(include=['number'])\n",
    "correlation_matrix = df_numeric.corr()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99bbc1d684b4659d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb3327121e007ec6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # Check features importance:\n",
    "\n",
    "from models import XGBoost\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "xgb_model = XGBoost()\n",
    "xgb_model.scale_and_split_data(X, y)\n",
    "\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "model.fit(xgb_model.X_train, xgb_model.y_train)\n",
    "xgb_model.model = model\n",
    "\n",
    "columns = list(feature_selector.df.columns)\n",
    "columns.remove(\"generation\")\n",
    "X_test_df = pd.DataFrame(xgb_model.X_test, columns=columns)\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "\n",
    "shap_values = explainer(X_test_df)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test_df, max_display=60)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a341809fe5a65fe4"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-08-19 14:35:59\u001B[0m - \u001B[34mmodel_main\u001B[0m - \u001B[1;30mINFO\u001B[0m - Csv file has bean read successfully\n",
      "\u001B[32m2025-08-19 14:36:02\u001B[0m - \u001B[34mmodel_main\u001B[0m - \u001B[1;30mINFO\u001B[0m - Some features have been added successfully\n",
      "\u001B[32m2025-08-19 14:36:02\u001B[0m - \u001B[34mmodel_main\u001B[0m - \u001B[1;30mINFO\u001B[0m - Rows have been selected successfully\n",
      "\u001B[32m2025-08-19 14:36:03\u001B[0m - \u001B[34mmodel_main\u001B[0m - \u001B[1;30mINFO\u001B[0m - Some features have been dropped successfully\n",
      "\u001B[32m2025-08-19 14:36:06\u001B[0m - \u001B[34mmodel_main\u001B[0m - \u001B[1;30mINFO\u001B[0m - Model has been trained successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: 7.42%, Test Error: 7.55%\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "project_root = \"U:/ML_project/bargh\"\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import pandas as pd\n",
    "from data_selector import Data_selector\n",
    "from feature_modifier import Feature_selector, Feature_adder\n",
    "from logs.logger import CustomLogger\n",
    "from models import Random_Forest, Linear, Polynomial, XGBoost\n",
    "\n",
    "logger = CustomLogger(name=\"model_main\", log_file_name='model_main.log').get_logger()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = os.path.join(project_root, \"data\", \"processed\", \"integrated.csv\")\n",
    "df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "logger.info(f\"Csv file has bean read successfully\")\n",
    "\n",
    "feature_adder = Feature_adder(df)\n",
    "feature_adder.add_season()\n",
    "feature_adder.create_feature_with_delay(\"temperature\", 3)\n",
    "feature_adder.create_feature_with_delay(\"generation\", 24)\n",
    "logger.info(f\"Some features have been added successfully\")\n",
    "\n",
    "data_selector = Data_selector(feature_adder.df)\n",
    "df_modified = data_selector.select(m_in_summer=True)\n",
    "logger.info(f\"Rows have been selected successfully\")\n",
    "\n",
    "feature_selector = Feature_selector(df_modified, \"generation\")\n",
    "feature_to_be_dropped = ['id', 'date', 'declare', 'require']\n",
    "less_important_feature = ['dew', 'apparent_temperature', 'precipitation', 'rain', 'snow',\n",
    "                          'evapotransporation', 'wind_speed', 'wind_direction']\n",
    "X, y = feature_selector.select(feature_to_be_dropped + less_important_feature)\n",
    "logger.info(f\"Some features have been dropped successfully\")\n",
    "\n",
    "# n_est = 100\n",
    "# depth = 30\n",
    "# model = Random_Forest()\n",
    "# model.scale_and_split_data(X, y)\n",
    "# model.fit(n_estimators=n_est, max_depth=depth)\n",
    "\n",
    "# model = Linear()\n",
    "# model.scale_and_split_data(X, y)\n",
    "# model.fit()\n",
    "\n",
    "# model = Polynomial()\n",
    "# model.scale_and_split_data(X, y)\n",
    "# model.fit()\n",
    "\n",
    "n_est = 100\n",
    "depth = 5\n",
    "model = XGBoost()\n",
    "model.scale_and_split_data(X, y)\n",
    "model.fit(n_estimators=n_est, max_depth=depth)\n",
    "\n",
    "logger.info(f\"Model has been trained successfully\")\n",
    "\n",
    "rmse_error_train, rmse_error_test = model.compute_rmse_error()\n",
    "print(f\"Train Error: {rmse_error_train:0.2f}%, Test Error: {rmse_error_test:0.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T11:06:06.164494500Z",
     "start_time": "2025-08-19T11:05:55.147941700Z"
    }
   },
   "id": "de6fe45733fdf903"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "project_root = \"U:/ML_project/bargh\"\n",
    "csv_path = os.path.join(project_root, \"data\", \"processed\", \"integrated.csv\")\n",
    "df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['datetime'] = df['date'] + pd.to_timedelta(df['hour'], unit='h')\n",
    "df = df.sort_values(by=['code', 'name', 'date', 'hour'])\n",
    "\n",
    "feature_to_be_dropped = ['id', 'date', 'declare', 'require', 'datetime']\n",
    "less_important_feature = ['dew', 'apparent_temperature', 'precipitation', 'rain', 'snow',\n",
    "                          'evapotransporation', 'wind_speed', 'wind_direction']\n",
    "\n",
    "df = df.drop(feature_to_be_dropped + less_important_feature, axis=1)\n",
    "\n",
    "n_rows = 24\n",
    "n_cols = df.shape[1]\n",
    "\n",
    "arr = df.to_numpy()\n",
    "\n",
    "new_rows = df.shape[0] // n_rows\n",
    "\n",
    "reshaped = arr[:new_rows * n_rows].reshape(new_rows, n_rows * n_cols)\n",
    "\n",
    "new_columns = []\n",
    "for i in range(n_rows):\n",
    "    for col in df.columns:\n",
    "        new_columns.append(f\"{col}_{i+1}\")\n",
    "\n",
    "new_df = pd.DataFrame(reshaped, columns=new_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T11:06:10.930758300Z",
     "start_time": "2025-08-19T11:06:07.158675700Z"
    }
   },
   "id": "688f3e3089394054"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "to_be_dropped_columns = []\n",
    "for col in ['name', 'code', 'hour']:\n",
    "    for i in range(24):\n",
    "        col_name = f\"{col}_{i+1}\"\n",
    "        if col_name in ['name_1', 'code_1']: continue\n",
    "        to_be_dropped_columns.append(col_name)\n",
    "        \n",
    "common_deleted_df = new_df.drop(to_be_dropped_columns, axis=1)\n",
    "\n",
    "categorical_cols = ['name_1', 'code_1'] + [f'value_{i+1}' for i in range(24)] + [f'status_{i+1}' for i in range(24)]\n",
    "final_df = pd.get_dummies(common_deleted_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "final_df = final_df.dropna()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T11:06:13.010265Z",
     "start_time": "2025-08-19T11:06:11.694969800Z"
    }
   },
   "id": "a30eacf63e604c45"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "1376"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T11:06:13.749028600Z",
     "start_time": "2025-08-19T11:06:13.715317200Z"
    }
   },
   "id": "3257f9355ee471a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "generation_columns = [f\"generation_{i+1}\" for i in range(24)]\n",
    "X = final_df.drop(columns=generation_columns)\n",
    "y = final_df[generation_columns]\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T11:06:17.453734200Z",
     "start_time": "2025-08-19T11:06:17.348554800Z"
    }
   },
   "id": "2983c5eb9eda588e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(34728, 1352)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T11:06:55.476933Z",
     "start_time": "2025-08-19T11:06:55.460229300Z"
    }
   },
   "id": "ff8a8bbdf714b919"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from models import Model\n",
    "group_model = Model()\n",
    "group_model.scale_and_split_data(X, y, y_is_flat=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:31.887402900Z",
     "start_time": "2025-08-19T11:07:29.315790800Z"
    }
   },
   "id": "d91c27bf9ab12557"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "multi_model = MultiOutputRegressor(xgb_model)\n",
    "\n",
    "multi_model.fit(group_model.X_train, group_model.y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-08-19T11:16:45.333364900Z"
    }
   },
   "id": "3ac908ca294edf9a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: 13.42%, Test Error: 14.14%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "y_pred_test = multi_model.predict(group_model.X_test)\n",
    "y_pred_train = multi_model.predict(group_model.X_train)\n",
    "y_pred_test_actual = group_model.scaler_y.inverse_transform(y_pred_test).ravel()\n",
    "y_pred_train_actual = group_model.scaler_y.inverse_transform(y_pred_train).ravel()\n",
    "y_test_actual = group_model.scaler_y.inverse_transform(group_model.y_test).ravel()\n",
    "y_train_actual = group_model.scaler_y.inverse_transform(group_model.y_train).ravel()\n",
    "\n",
    "rmse_test_actual = (mean_squared_error(y_test_actual, y_pred_test_actual) ** 0.5 / np.mean(y_test_actual)) * 100\n",
    "rmse_train_actual = (mean_squared_error(y_train_actual, y_pred_train_actual) ** 0.5 / np.mean(y_train_actual)) * 100\n",
    "\n",
    "print(f\"Train Error: {rmse_train_actual:0.2f}%, Test Error: {rmse_test_actual:0.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-19T11:14:51.089505600Z",
     "start_time": "2025-08-19T11:14:49.115892300Z"
    }
   },
   "id": "53b6734350cd6e95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "73e0e20cf0de76f0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
